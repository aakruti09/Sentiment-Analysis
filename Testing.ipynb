{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a85fa0",
   "metadata": {},
   "source": [
    "### For testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0785615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b28369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "path1 = os.path.join(current_path,\"aclImdb\")\n",
    "train_folder=os.path.join(path1,\"train\")\n",
    "os.listdir(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7881a193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data=tf.keras.preprocessing.text_dataset_from_directory('aclImdb/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c239368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(input_data):\n",
    "    # Converting each word to lower case because vocabulary is also in lower case in 'imdb.vocab'\n",
    "    lower = tf.strings.lower(input_data)\n",
    "    # Removing new line characters from movie reviews\n",
    "    space = tf.strings.regex_replace(lower, \"<br />\", \" \")\n",
    "    # Removing punctuations from sentences \n",
    "    clean_punch = tf.strings.regex_replace(space, '[%s]' %re.escape(string.punctuation), '')\n",
    "    return clean_punch\n",
    "\n",
    "numerical_text_layer = TextVectorization(standardize=clean_text, vocabulary='aclImdb/imdb.vocab',\n",
    "    output_mode='int', output_sequence_length=500)\n",
    "\n",
    "def print_numerical_text(text, label):\n",
    "    # Converting text tensor shape from () to (1,) because of numerical_text_layer.\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    # print(text.shape)\n",
    "    # Applied vocabulary on text data and returned it the numerical text and label.\n",
    "    return numerical_text_layer(text), label\n",
    "\n",
    "numerical_test_data = test_data.map(print_numerical_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e49b0",
   "metadata": {},
   "source": [
    "### Loading the model saved from models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad7fd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 16)           1432464   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,432,753\n",
      "Trainable params: 1,432,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "testing_model=keras.models.load_model('models/20912881_NLP_model.h5')\n",
    "testing_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f386c02",
   "metadata": {},
   "source": [
    "#### Calculating the loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cdd4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 463s 585ms/step - loss: 0.3316 - accuracy: 0.8812\n",
      "For Test dataset\n",
      "Accuracy: 0.8812400102615356\n",
      "Loss: 0.33158448338508606\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = testing_model.evaluate(numerical_test_data)\n",
    "print(\"For Test dataset\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Loss:\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8f2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
